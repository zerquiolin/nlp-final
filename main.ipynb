{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mental Health NLP Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils import get_device\n",
    "from src.inference import predict_text_rnn\n",
    "from src.training.training import (\n",
    "    train_rnn,\n",
    "    train_baselines,\n",
    "    train_transformer_experiment,\n",
    ")\n",
    "\n",
    "from src.data.preprocess import clean_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"data/mental_health.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority baseline metrics:\n",
      "{'accuracy': 0.3102619258509427, 'f1_macro': 0.06765537697454646, 'classification_report': {'Anxiety': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 576.0}, 'Bipolar': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 417.0}, 'Depression': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2311.0}, 'Normal': {'precision': 0.3102619258509427, 'recall': 1.0, 'f1-score': 0.4735876388218252, 'support': 2452.0}, 'Personality disorder': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 161.0}, 'Stress': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 388.0}, 'Suicidal': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1598.0}, 'accuracy': 0.3102619258509427, 'macro avg': {'precision': 0.04432313226442038, 'recall': 0.14285714285714285, 'f1-score': 0.06765537697454646, 'support': 7903.0}, 'weighted avg': {'precision': 0.09626246263273586, 'recall': 0.3102619258509427, 'f1-score': 0.14693621288006015, 'support': 7903.0}}, 'confusion_matrix': [[0, 0, 0, 576, 0, 0, 0], [0, 0, 0, 417, 0, 0, 0], [0, 0, 0, 2311, 0, 0, 0], [0, 0, 0, 2452, 0, 0, 0], [0, 0, 0, 161, 0, 0, 0], [0, 0, 0, 388, 0, 0, 0], [0, 0, 0, 1598, 0, 0, 0]]}\n",
      "\n",
      "TF-IDF + Logistic Regression metrics:\n",
      "{'accuracy': 0.7762874857648994, 'f1_macro': 0.7207510089822521, 'classification_report': {'Anxiety': {'precision': 0.8215686274509804, 'recall': 0.7274305555555556, 'f1-score': 0.7716390423572744, 'support': 576.0}, 'Bipolar': {'precision': 0.861671469740634, 'recall': 0.7170263788968825, 'f1-score': 0.7827225130890052, 'support': 417.0}, 'Depression': {'precision': 0.7286073825503355, 'recall': 0.7516226741670272, 'f1-score': 0.7399361022364217, 'support': 2311.0}, 'Normal': {'precision': 0.8324496288441146, 'recall': 0.9604404567699837, 'f1-score': 0.8918765385343685, 'support': 2452.0}, 'Personality disorder': {'precision': 0.8571428571428571, 'recall': 0.4472049689440994, 'f1-score': 0.5877551020408164, 'support': 161.0}, 'Stress': {'precision': 0.7213740458015268, 'recall': 0.48711340206185566, 'f1-score': 0.5815384615384616, 'support': 388.0}, 'Suicidal': {'precision': 0.7155346334902488, 'recall': 0.6658322903629537, 'f1-score': 0.6897893030794165, 'support': 1598.0}, 'accuracy': 0.7762874857648994, 'macro avg': {'precision': 0.7911926635743853, 'recall': 0.6795243895369083, 'f1-score': 0.7207510089822521, 'support': 7903.0}, 'weighted avg': {'precision': 0.7742422064256121, 'recall': 0.7762874857648994, 'f1-score': 0.770629100586733, 'support': 7903.0}}, 'confusion_matrix': [[419, 14, 45, 78, 0, 18, 2], [16, 299, 49, 36, 2, 11, 4], [21, 17, 1737, 135, 7, 10, 384], [12, 5, 39, 2355, 2, 23, 16], [6, 3, 43, 24, 72, 10, 3], [36, 9, 73, 66, 1, 189, 14], [0, 0, 398, 135, 0, 1, 1064]]}\n",
      "\n",
      "TF-IDF + Linear SVM metrics:\n",
      "{'accuracy': 0.7770466911299506, 'f1_macro': 0.7453105904976329, 'classification_report': {'Anxiety': {'precision': 0.8249097472924187, 'recall': 0.7934027777777778, 'f1-score': 0.8088495575221238, 'support': 576.0}, 'Bipolar': {'precision': 0.8398950131233596, 'recall': 0.7673860911270983, 'f1-score': 0.8020050125313283, 'support': 417.0}, 'Depression': {'precision': 0.7317605941459152, 'recall': 0.7247944612721765, 'f1-score': 0.7282608695652174, 'support': 2311.0}, 'Normal': {'precision': 0.8593576965669989, 'recall': 0.9494290375203915, 'f1-score': 0.9021507459794613, 'support': 2452.0}, 'Personality disorder': {'precision': 0.8, 'recall': 0.6459627329192547, 'f1-score': 0.7147766323024055, 'support': 161.0}, 'Stress': {'precision': 0.7035714285714286, 'recall': 0.5077319587628866, 'f1-score': 0.5898203592814372, 'support': 388.0}, 'Suicidal': {'precision': 0.6794871794871795, 'recall': 0.6633291614518148, 'f1-score': 0.6713109563014567, 'support': 1598.0}, 'accuracy': 0.7770466911299506, 'macro avg': {'precision': 0.7769973798839, 'recall': 0.7217194601187715, 'f1-score': 0.7453105904976329, 'support': 7903.0}, 'weighted avg': {'precision': 0.7732803071077556, 'recall': 0.7770466911299506, 'f1-score': 0.773390127728303, 'support': 7903.0}}, 'confusion_matrix': [[457, 12, 34, 50, 1, 18, 4], [15, 320, 37, 26, 4, 10, 5], [23, 21, 1675, 106, 12, 19, 455], [13, 6, 57, 2328, 4, 24, 20], [6, 4, 18, 19, 104, 8, 2], [38, 15, 48, 71, 5, 197, 14], [2, 3, 420, 109, 0, 4, 1060]]}\n"
     ]
    }
   ],
   "source": [
    "baseline_results = train_baselines(CSV_PATH)\n",
    "\n",
    "print(\"Majority baseline metrics:\")\n",
    "print(baseline_results[\"majority\"])\n",
    "\n",
    "print(\"\\nTF-IDF + Logistic Regression metrics:\")\n",
    "print(baseline_results[\"tfidf_logreg\"])\n",
    "\n",
    "print(\"\\nTF-IDF + Linear SVM metrics:\")\n",
    "print(baseline_results[\"tfidf_svm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/32: 100%|██████████| 1153/1153 [00:12<00:00, 92.03it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 276.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.0326, val_acc=0.6741, val_f1=0.5321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.87it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 273.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss=0.7149, val_acc=0.7240, val_f1=0.6042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.82it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 273.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss=0.5862, val_acc=0.7274, val_f1=0.6491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.60it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 274.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss=0.4836, val_acc=0.7447, val_f1=0.6735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.77it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 275.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss=0.4051, val_acc=0.7460, val_f1=0.6888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.97it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 267.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss=0.3319, val_acc=0.7468, val_f1=0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/32: 100%|██████████| 1153/1153 [00:12<00:00, 93.53it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 272.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss=0.2702, val_acc=0.7545, val_f1=0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/32: 100%|██████████| 1153/1153 [00:12<00:00, 92.78it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 276.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss=0.2227, val_acc=0.7508, val_f1=0.6941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.93it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 266.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss=0.1773, val_acc=0.7488, val_f1=0.7027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.42it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 273.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss=0.1452, val_acc=0.7506, val_f1=0.6892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.70it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 276.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_loss=0.1163, val_acc=0.7515, val_f1=0.7047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.79it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 272.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_loss=0.0901, val_acc=0.7402, val_f1=0.6927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.77it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 272.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_loss=0.0819, val_acc=0.7431, val_f1=0.6933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/32: 100%|██████████| 1153/1153 [00:12<00:00, 93.01it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 275.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_loss=0.0704, val_acc=0.7407, val_f1=0.6869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/32: 100%|██████████| 1153/1153 [00:12<00:00, 95.04it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 290.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_loss=0.0615, val_acc=0.7423, val_f1=0.6925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.35it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 270.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_loss=0.0568, val_acc=0.7408, val_f1=0.6890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.83it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 272.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_loss=0.0486, val_acc=0.7480, val_f1=0.6973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.73it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 272.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: train_loss=0.0418, val_acc=0.7382, val_f1=0.6824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.33it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 269.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: train_loss=0.0415, val_acc=0.7442, val_f1=0.6977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.83it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 271.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: train_loss=0.0440, val_acc=0.7439, val_f1=0.6963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/32: 100%|██████████| 1153/1153 [00:12<00:00, 93.60it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 272.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: train_loss=0.0368, val_acc=0.7421, val_f1=0.6990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/32: 100%|██████████| 1153/1153 [00:12<00:00, 90.43it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 237.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: train_loss=0.0367, val_acc=0.7408, val_f1=0.6903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.81it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 271.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: train_loss=0.0372, val_acc=0.7431, val_f1=0.7003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.83it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 273.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: train_loss=0.0307, val_acc=0.7425, val_f1=0.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.92it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 273.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: train_loss=0.0341, val_acc=0.7437, val_f1=0.6918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.67it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 272.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: train_loss=0.0277, val_acc=0.7356, val_f1=0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.60it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 270.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: train_loss=0.0331, val_acc=0.7472, val_f1=0.7006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/32: 100%|██████████| 1153/1153 [00:12<00:00, 95.08it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 271.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: train_loss=0.0315, val_acc=0.7454, val_f1=0.6997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.93it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 273.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: train_loss=0.0293, val_acc=0.7445, val_f1=0.6941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.93it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 266.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: train_loss=0.0250, val_acc=0.7412, val_f1=0.6882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/32: 100%|██████████| 1153/1153 [00:12<00:00, 94.89it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 269.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train_loss=0.0256, val_acc=0.7418, val_f1=0.6890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/32: 100%|██████████| 1153/1153 [00:12<00:00, 95.12it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:00<00:00, 272.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: train_loss=0.0244, val_acc=0.7439, val_f1=0.6952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 230.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: 0.7382006832848286 0.6872085557596751\n",
      "LSTM test metrics: {'accuracy': 0.7382006832848286, 'f1_macro': 0.6872085557596751, 'classification_report': {'Anxiety': {'precision': 0.7896678966789668, 'recall': 0.7430555555555556, 'f1-score': 0.7656529516994633, 'support': 576.0}, 'Bipolar': {'precision': 0.781491002570694, 'recall': 0.7290167865707434, 'f1-score': 0.7543424317617866, 'support': 417.0}, 'Depression': {'precision': 0.6714285714285714, 'recall': 0.6914755517092168, 'f1-score': 0.6813046258793434, 'support': 2311.0}, 'Normal': {'precision': 0.8884086444007858, 'recall': 0.9221044045676998, 'f1-score': 0.9049429657794676, 'support': 2452.0}, 'Personality disorder': {'precision': 0.5517241379310345, 'recall': 0.4968944099378882, 'f1-score': 0.5228758169934641, 'support': 161.0}, 'Stress': {'precision': 0.5788113695090439, 'recall': 0.5773195876288659, 'f1-score': 0.5780645161290323, 'support': 388.0}, 'Suicidal': {'precision': 0.6198019801980198, 'recall': 0.5876095118898623, 'f1-score': 0.6032765820751687, 'support': 1598.0}, 'accuracy': 0.7382006832848286, 'macro avg': {'precision': 0.6973333718167308, 'recall': 0.6782108296942618, 'f1-score': 0.6872085557596751, 'support': 7903.0}, 'weighted avg': {'precision': 0.7357496954490776, 'recall': 0.7382006832848286, 'f1-score': 0.7366190122323301, 'support': 7903.0}}, 'confusion_matrix': [[428, 21, 39, 36, 12, 31, 9], [21, 304, 42, 19, 8, 18, 5], [33, 38, 1598, 87, 20, 31, 504], [18, 6, 61, 2261, 9, 56, 41], [10, 6, 27, 17, 80, 16, 5], [26, 8, 65, 40, 13, 224, 12], [6, 6, 548, 85, 3, 11, 939]]}\n"
     ]
    }
   ],
   "source": [
    "rnn_result = train_rnn(CSV_PATH, model_type=\"lstm\")\n",
    "print(\"LSTM test metrics:\", rnn_result[\"test_metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/32: 100%|██████████| 1153/1153 [00:34<00:00, 33.44it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 127.37it/s]\n",
      "/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.0412, val_acc=0.6878, val_f1=0.4747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/32: 100%|██████████| 1153/1153 [00:34<00:00, 33.53it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 127.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss=0.6970, val_acc=0.7426, val_f1=0.6360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/32: 100%|██████████| 1153/1153 [00:34<00:00, 33.83it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 133.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss=0.5542, val_acc=0.7493, val_f1=0.6792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/32: 100%|██████████| 1153/1153 [00:34<00:00, 33.02it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 128.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss=0.4535, val_acc=0.7482, val_f1=0.6843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/32: 100%|██████████| 1153/1153 [00:34<00:00, 32.99it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:02<00:00, 123.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss=0.3670, val_acc=0.7558, val_f1=0.7006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/32: 100%|██████████| 1153/1153 [00:36<00:00, 31.93it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:02<00:00, 114.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss=0.2878, val_acc=0.7456, val_f1=0.6992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/32: 100%|██████████| 1153/1153 [00:36<00:00, 31.85it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 126.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss=0.2261, val_acc=0.7499, val_f1=0.7002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/32: 100%|██████████| 1153/1153 [00:36<00:00, 31.91it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 128.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss=0.1719, val_acc=0.7459, val_f1=0.6976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/32: 100%|██████████| 1153/1153 [00:35<00:00, 32.09it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 125.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss=0.1362, val_acc=0.7413, val_f1=0.6901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/32: 100%|██████████| 1153/1153 [00:35<00:00, 32.05it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 123.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss=0.1057, val_acc=0.7363, val_f1=0.6891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/32: 100%|██████████| 1153/1153 [00:35<00:00, 32.25it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 125.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_loss=0.0898, val_acc=0.7377, val_f1=0.6869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/32: 100%|██████████| 1153/1153 [00:35<00:00, 32.13it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 124.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_loss=0.0726, val_acc=0.7316, val_f1=0.6762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/32: 100%|██████████| 1153/1153 [00:35<00:00, 32.31it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 124.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_loss=0.0649, val_acc=0.7377, val_f1=0.6913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/32: 100%|██████████| 1153/1153 [00:35<00:00, 32.19it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 124.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_loss=0.0607, val_acc=0.7389, val_f1=0.6911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/32: 100%|██████████| 1153/1153 [00:35<00:00, 32.52it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 124.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_loss=0.0502, val_acc=0.7379, val_f1=0.6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/32: 100%|██████████| 1153/1153 [00:35<00:00, 32.22it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 124.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_loss=0.0478, val_acc=0.7331, val_f1=0.6859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/32: 100%|██████████| 1153/1153 [00:35<00:00, 32.50it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 124.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_loss=0.0468, val_acc=0.7356, val_f1=0.6888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/32: 100%|██████████| 1153/1153 [00:35<00:00, 32.44it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 125.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: train_loss=0.0456, val_acc=0.7355, val_f1=0.6889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/32: 100%|██████████| 1153/1153 [00:35<00:00, 32.21it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 138.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: train_loss=0.0378, val_acc=0.7346, val_f1=0.6946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/32: 100%|██████████| 1153/1153 [00:35<00:00, 32.22it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 142.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: train_loss=0.0361, val_acc=0.7308, val_f1=0.6783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/32: 100%|██████████| 1153/1153 [00:33<00:00, 34.93it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 137.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: train_loss=0.0440, val_acc=0.7222, val_f1=0.6731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/32: 100%|██████████| 1153/1153 [00:33<00:00, 34.61it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 141.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: train_loss=0.0412, val_acc=0.7336, val_f1=0.6845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/32: 100%|██████████| 1153/1153 [00:33<00:00, 34.66it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 137.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: train_loss=0.0329, val_acc=0.7317, val_f1=0.6834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/32: 100%|██████████| 1153/1153 [00:33<00:00, 34.91it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 139.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: train_loss=0.0347, val_acc=0.7334, val_f1=0.6918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/32: 100%|██████████| 1153/1153 [00:32<00:00, 35.23it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 139.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: train_loss=0.0312, val_acc=0.7330, val_f1=0.6853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/32: 100%|██████████| 1153/1153 [00:33<00:00, 34.88it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 142.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: train_loss=0.0338, val_acc=0.7326, val_f1=0.6868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/32: 100%|██████████| 1153/1153 [00:32<00:00, 35.34it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 137.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: train_loss=0.0267, val_acc=0.7278, val_f1=0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/32: 100%|██████████| 1153/1153 [00:33<00:00, 34.82it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 138.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: train_loss=0.0346, val_acc=0.7311, val_f1=0.6846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/32: 100%|██████████| 1153/1153 [00:32<00:00, 35.04it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 141.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: train_loss=0.0301, val_acc=0.7265, val_f1=0.6804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/32: 100%|██████████| 1153/1153 [00:32<00:00, 35.12it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 139.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: train_loss=0.0273, val_acc=0.7325, val_f1=0.6955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/32: 100%|██████████| 1153/1153 [00:32<00:00, 35.02it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 142.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train_loss=0.0306, val_acc=0.7287, val_f1=0.6785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/32: 100%|██████████| 1153/1153 [00:32<00:00, 35.28it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 141.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: train_loss=0.0266, val_acc=0.7304, val_f1=0.6834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RNN: 100%|██████████| 247/247 [00:01<00:00, 138.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: 0.725673794761483 0.6735423396087429\n",
      "GRU test metrics: {'accuracy': 0.725673794761483, 'f1_macro': 0.6735423396087429, 'classification_report': {'Anxiety': {'precision': 0.7641509433962265, 'recall': 0.703125, 'f1-score': 0.7323688969258589, 'support': 576.0}, 'Bipolar': {'precision': 0.7482678983833718, 'recall': 0.7769784172661871, 'f1-score': 0.7623529411764706, 'support': 417.0}, 'Depression': {'precision': 0.6552567237163814, 'recall': 0.6958026828212894, 'f1-score': 0.6749213011542498, 'support': 2311.0}, 'Normal': {'precision': 0.8872, 'recall': 0.9045676998368679, 'f1-score': 0.8957996768982229, 'support': 2452.0}, 'Personality disorder': {'precision': 0.5189873417721519, 'recall': 0.5093167701863354, 'f1-score': 0.5141065830721003, 'support': 161.0}, 'Stress': {'precision': 0.5590551181102362, 'recall': 0.5489690721649485, 'f1-score': 0.5539661898569571, 'support': 388.0}, 'Suicidal': {'precision': 0.6116102280580511, 'recall': 0.5538172715894869, 'f1-score': 0.5812807881773399, 'support': 1598.0}, 'accuracy': 0.725673794761483, 'macro avg': {'precision': 0.677789750490917, 'recall': 0.6703681305521592, 'f1-score': 0.6735423396087429, 'support': 7903.0}, 'weighted avg': {'precision': 0.7237396985726311, 'recall': 0.725673794761483, 'f1-score': 0.7241030414865612, 'support': 7903.0}}, 'confusion_matrix': [[405, 33, 44, 37, 14, 37, 6], [19, 324, 34, 9, 8, 18, 5], [30, 31, 1608, 89, 21, 35, 497], [29, 13, 88, 2218, 12, 52, 40], [11, 12, 28, 14, 82, 12, 2], [29, 13, 57, 48, 16, 213, 12], [7, 7, 595, 85, 5, 14, 885]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gru_result = train_rnn(CSV_PATH, model_type=\"gru\")\n",
    "print(\"GRU test metrics:\", gru_result[\"test_metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Tiny Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='577' max='577' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [577/577 07:21, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.577800</td>\n",
       "      <td>0.525323</td>\n",
       "      <td>0.792837</td>\n",
       "      <td>0.748099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG15XFamilyCommandBuffer: 0x3e20cdcf0>\n",
      "    label = <none> \n",
      "    device = <AGXG15SDevice: 0x3a0d6b200>\n",
      "        name = Apple M3 Pro \n",
      "    commandQueue = <AGXG15XFamilyCommandQueue: 0x3a58cbe00>\n",
      "        label = <none> \n",
      "        device = <AGXG15SDevice: 0x3a0d6b200>\n",
      "            name = Apple M3 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 36.86 GiB, other allocations: 6.01 GiB, max allowed: 47.74 GiB). Tried to allocate 5.79 GiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m transformer_result = \u001b[43mtrain_transformer_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCSV_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTransformer test metrics:\u001b[39m\u001b[33m\"\u001b[39m, transformer_result[\u001b[33m\"\u001b[39m\u001b[33mtest_metrics\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Study/University/III/Natural Language Processing/Project/src/training/training.py:291\u001b[39m, in \u001b[36mtrain_transformer_experiment\u001b[39m\u001b[34m(csv_path)\u001b[39m\n\u001b[32m    286\u001b[39m device = model.device\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    288\u001b[39m     inputs = {\n\u001b[32m    289\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m: torch.tensor(test_enc[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m], device=device),\n\u001b[32m    290\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m: torch.tensor(test_enc[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m], device=device),\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     }\n\u001b[32m    292\u001b[39m     outputs = model(**inputs)\n\u001b[32m    293\u001b[39m preds = outputs.logits.argmax(-\u001b[32m1\u001b[39m).cpu().numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:905\u001b[39m, in \u001b[36mDistilBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    897\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    898\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m    899\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m    900\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m    901\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m    902\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    903\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m distilbert_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    913\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    914\u001b[39m hidden_state = distilbert_output[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[32m    915\u001b[39m pooled_output = hidden_state[:, \u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:724\u001b[39m, in \u001b[36mDistilBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation == \u001b[33m\"\u001b[39m\u001b[33msdpa\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m head_mask_is_none \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[32m    720\u001b[39m         attention_mask = _prepare_4d_attention_mask_for_sdpa(\n\u001b[32m    721\u001b[39m             attention_mask, embeddings.dtype, tgt_len=input_shape[\u001b[32m1\u001b[39m]\n\u001b[32m    722\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:531\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    529\u001b[39m     all_hidden_states = all_hidden_states + (hidden_state,)\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m hidden_state = layer_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:466\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions)\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[33;03mParameters:\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[33;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    463\u001b[39m \u001b[33;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m sa_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[32m    475\u001b[39m     sa_output, sa_weights = sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:392\u001b[39m, in \u001b[36mDistilBertSdpaAttention.forward\u001b[39m\u001b[34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[39m\n\u001b[32m    389\u001b[39m k = shape(\u001b[38;5;28mself\u001b[39m.k_lin(key))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[32m    390\u001b[39m v = shape(\u001b[38;5;28mself\u001b[39m.v_lin(value))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m attn_output = unshape(attn_output)\n\u001b[32m    402\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.out_lin(attn_output)\n",
      "\u001b[31mRuntimeError\u001b[39m: MPS backend out of memory (MPS allocated: 36.86 GiB, other allocations: 6.01 GiB, max allowed: 47.74 GiB). Tried to allocate 5.79 GiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "transformer_result = train_transformer_experiment(CSV_PATH)\n",
    "print(\"Transformer test metrics:\", transformer_result[\"test_metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference & Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c21a32a1",
   "metadata": {},
   "source": [
    "## Model Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4726e12",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformer_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     16\u001b[39m     model_metrics.append({\n\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: name,\n\u001b[32m     18\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m: m[\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     19\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mf1_macro\u001b[39m\u001b[33m\"\u001b[39m: m[\u001b[33m\"\u001b[39m\u001b[33mf1_macro\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     20\u001b[39m     })\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Tiny transformer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m m = \u001b[43mtransformer_result\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mtest_metrics\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     24\u001b[39m model_metrics.append({\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtiny_transformer\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m: m[\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mf1_macro\u001b[39m\u001b[33m\"\u001b[39m: m[\u001b[33m\"\u001b[39m\u001b[33mf1_macro\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     28\u001b[39m })\n\u001b[32m     30\u001b[39m metrics_df = pd.DataFrame(model_metrics)\n",
      "\u001b[31mNameError\u001b[39m: name 'transformer_result' is not defined"
     ]
    }
   ],
   "source": [
    "# Aggregate metrics for all models into a DataFrame\n",
    "model_metrics = []\n",
    "\n",
    "# Baselines\n",
    "for name in [\"majority\", \"tfidf_logreg\", \"tfidf_svm\"]:\n",
    "    m = baseline_results[name]\n",
    "    model_metrics.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": m[\"accuracy\"],\n",
    "        \"f1_macro\": m[\"f1_macro\"],\n",
    "    })\n",
    "\n",
    "# RNNs\n",
    "for name, res in [(\"rnn_lstm\", rnn_result), (\"rnn_gru\", gru_result)]:\n",
    "    m = res[\"test_metrics\"]\n",
    "    model_metrics.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": m[\"accuracy\"],\n",
    "        \"f1_macro\": m[\"f1_macro\"],\n",
    "    })\n",
    "\n",
    "# Tiny transformer\n",
    "m = transformer_result[\"test_metrics\"]\n",
    "model_metrics.append({\n",
    "    \"model\": \"tiny_transformer\",\n",
    "    \"accuracy\": m[\"accuracy\"],\n",
    "    \"f1_macro\": m[\"f1_macro\"],\n",
    "})\n",
    "\n",
    "metrics_df = pd.DataFrame(model_metrics)\n",
    "\n",
    "# Ranking by F1-macro\n",
    "metrics_df = metrics_df.sort_values(\"f1_macro\", ascending=False).reset_index(drop=True)\n",
    "metrics_df[\"rank\"] = metrics_df.index + 1\n",
    "\n",
    "print(\"Model ranking (by macro F1):\")\n",
    "\n",
    "display(metrics_df)\n",
    "\n",
    "# Grouped bar chart for accuracy and F1-macro\n",
    "plt.figure(figsize=(8, 5))\n",
    "x = range(len(metrics_df))\n",
    "bar_width = 0.35\n",
    "\n",
    "plt.bar([i - bar_width/2 for i in x], metrics_df[\"accuracy\"], width=bar_width, label=\"Accuracy\")\n",
    "plt.bar([i + bar_width/2 for i in x], metrics_df[\"f1_macro\"], width=bar_width, label=\"F1-macro\")\n",
    "\n",
    "plt.xticks(list(x), metrics_df[\"model\"], rotation=45)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Model Performance Comparison\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b34b04",
   "metadata": {},
   "source": [
    "### Confusion Matrices per Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a4b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm as cm_color\n",
    "\n",
    "label_names = baseline_results[\"label_encoder\"].classes_.tolist()\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\", cmap=cm_color.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(\n",
    "        xticks=range(len(labels)),\n",
    "        yticks=range(len(labels)),\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        ylabel=\"True label\",\n",
    "        xlabel=\"Predicted label\",\n",
    "        title=title,\n",
    "    )\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    # annotate\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            ax.text(j, i, cm[i][j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "    plt.tight_layout()\n",
    "    return ax\n",
    "\n",
    "# Collect confusion matrices\n",
    "cms = [\n",
    "    (\"majority\", baseline_results[\"majority\"][\"confusion_matrix\"]),\n",
    "    (\"tfidf_logreg\", baseline_results[\"tfidf_logreg\"][\"confusion_matrix\"]),\n",
    "    (\"tfidf_svm\", baseline_results[\"tfidf_svm\"][\"confusion_matrix\"]),\n",
    "    (\"rnn_lstm\", rnn_result[\"test_metrics\"][\"confusion_matrix\"]),\n",
    "    (\"rnn_gru\", gru_result[\"test_metrics\"][\"confusion_matrix\"]),\n",
    "    (\"tiny_transformer\", transformer_result[\"test_metrics\"][\"confusion_matrix\"]),\n",
    "]\n",
    "\n",
    "# Plot in a grid\n",
    "plt.figure(figsize=(14, 10))\n",
    "for idx, (name, cm_vals) in enumerate(cms, start=1):\n",
    "    plt.subplot(2, 3, idx)\n",
    "    plt.imshow(cm_vals, interpolation=\"nearest\", cmap=cm_color.Blues)\n",
    "    plt.title(name)\n",
    "    plt.xticks(range(len(label_names)), label_names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(len(label_names)), label_names)\n",
    "    for i in range(len(label_names)):\n",
    "        for j in range(len(label_names)):\n",
    "            plt.text(j, i, cm_vals[i][j], ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1d9f8d",
   "metadata": {},
   "source": [
    "## Sample Predictions Across Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e56ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sample texts: one per distinct category (up to 5)\n",
    "label_encoder = rnn_result[\"label_encoder\"]\n",
    "labels = label_encoder.classes_.tolist()\n",
    "\n",
    "def make_sample_for_label(label: str) -> str:\n",
    "    lower = label.lower()\n",
    "    if \"depress\" in lower:\n",
    "        return \"I feel sad, empty, and unmotivated most days, like nothing is worth it.\"\n",
    "    if \"anx\" in lower:\n",
    "        return \"My heart races all the time and I cannot stop worrying about everything.\"\n",
    "    if \"stress\" in lower:\n",
    "        return \"Work and life are overwhelming right now, I feel under constant pressure.\"\n",
    "    if \"suic\" in lower or \"self\" in lower:\n",
    "        return \"Lately I have been thinking that people would be better off without me.\"\n",
    "    if \"normal\" in lower or \"none\" in lower or \"control\" in lower:\n",
    "        return \"I have been feeling okay lately, managing my responsibilities without much trouble.\"\n",
    "    return f\"This is an example statement that might be categorized as '{label}' in a mental health context.\"\n",
    "\n",
    "sample_texts = []\n",
    "for label in labels[:5]:\n",
    "    sample_texts.append((label, make_sample_for_label(label)))\n",
    "\n",
    "vec_svm = baseline_results[\"vec_svm\"]\n",
    "clf_svm = baseline_results[\"clf_svm\"]\n",
    "tokenizer = transformer_result[\"tokenizer\"]\n",
    "transformer_model = transformer_result[\"model\"]\n",
    "device = get_device()\n",
    "transformer_model.to(device)\n",
    "rnn_model = rnn_result[\"model\"]\n",
    "rnn_model.to(device)\n",
    "word2idx = rnn_result[\"word2idx\"]\n",
    "\n",
    "print(\"Sample predictions (label, text, predicted by each model):\\n\")\n",
    "\n",
    "for true_label, text in sample_texts:\n",
    "    cleaned = clean_text(text)\n",
    "    # Baseline SVM\n",
    "    X_vec = vec_svm.transform([cleaned])\n",
    "    svm_pred_idx = clf_svm.predict(X_vec)[0]\n",
    "    svm_pred = label_encoder.inverse_transform([svm_pred_idx])[0]\n",
    "\n",
    "    # RNN LSTM\n",
    "    rnn_pred, rnn_conf = predict_text_rnn(\n",
    "        text,\n",
    "        rnn_model,\n",
    "        word2idx,\n",
    "        label_encoder,\n",
    "        device,\n",
    "    )\n",
    "\n",
    "    # Tiny transformer\n",
    "    enc = tokenizer(\n",
    "        [text],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = transformer_model(**enc)\n",
    "        probs = torch.softmax(outputs.logits, dim=-1)[0].cpu().numpy()\n",
    "        pred_idx = probs.argmax()\n",
    "    transformer_pred = label_encoder.inverse_transform([pred_idx])[0]\n",
    "\n",
    "    print(f\"True label: {true_label}\")\n",
    "    print(f\"Text      : {text}\")\n",
    "    print(f\"  TF-IDF + SVM       → {svm_pred}\")\n",
    "    print(f\"  RNN (LSTM)         → {rnn_pred} (conf={rnn_conf:.3f})\")\n",
    "    print(f\"  Tiny Transformer   → {transformer_pred}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa580c",
   "metadata": {},
   "source": [
    "## Qualitative Error Analysis (TF-IDF + SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a8c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a few misclassified examples for the TF-IDF + SVM model\n",
    "from src.data.preprocess import load_data, encode_labels\n",
    "\n",
    "df_all = load_data(CSV_PATH)\n",
    "# Use the same label encoder as in training\n",
    "le = baseline_results[\"label_encoder\"]\n",
    "df_all[\"label\"] = le.transform(df_all[\"status\"])\n",
    "\n",
    "texts = df_all[\"clean_text\"].tolist()\n",
    "true_labels = df_all[\"label\"].tolist()\n",
    "\n",
    "vec_svm = baseline_results[\"vec_svm\"]\n",
    "clf_svm = baseline_results[\"clf_svm\"]\n",
    "\n",
    "X_all = vec_svm.transform(texts)\n",
    "pred_labels = clf_svm.predict(X_all)\n",
    "\n",
    "mis_indices = [i for i in range(len(texts)) if pred_labels[i] != true_labels[i]]\n",
    "\n",
    "print(f\"Total samples: {len(texts)}, misclassified by SVM: {len(mis_indices)}\")\n",
    "\n",
    "for idx in mis_indices[:5]:\n",
    "    text = texts[idx]\n",
    "    true_lab = le.inverse_transform([true_labels[idx]])[0]\n",
    "    pred_lab = le.inverse_transform([pred_labels[idx]])[0]\n",
    "    print(\"\\n--- Misclassified example ---\")\n",
    "    print(\"Text         :\", text)\n",
    "    print(\"True label   :\", true_lab)\n",
    "    print(\"Predicted    :\", pred_lab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
