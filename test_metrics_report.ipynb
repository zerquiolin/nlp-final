{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "753a21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.training import train_baselines\n",
    "from src.data.preprocess import load_data, encode_labels, split_data\n",
    "from src.evaluation.metrics_report import generate_report  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31021761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\calex\\miniconda3\\envs\\nlp_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\calex\\miniconda3\\envs\\nlp_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\calex\\miniconda3\\envs\\nlp_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM report files: {'metrics_json': 'reports\\\\tfidf_svm_test_metrics.json', 'classification_csv': 'reports\\\\tfidf_svm_test_classification_report.csv', 'confusion_png': 'reports\\\\tfidf_svm_test_confusion_matrix.png'}\n",
      "LogReg report files: {'metrics_json': 'reports\\\\tfidf_logreg_test_metrics.json', 'classification_csv': 'reports\\\\tfidf_logreg_test_classification_report.csv', 'confusion_png': 'reports\\\\tfidf_logreg_test_confusion_matrix.png', 'roc_png': 'reports\\\\tfidf_logreg_test_roc.png', 'pr_png': 'reports\\\\tfidf_logreg_test_pr.png', 'calibration_png': 'reports\\\\tfidf_logreg_test_calibration.png'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CSV_PATH = \"data/mental_health.csv\"\n",
    "\n",
    "def main():\n",
    "    # 1) Entrena solo los baselines (rápido)\n",
    "    baseline_results = train_baselines(CSV_PATH)\n",
    "\n",
    "    # 2) Construye test_df desde los mismos pasos que train_baselines\n",
    "    df = load_data(CSV_PATH)\n",
    "    df, le = encode_labels(df)\n",
    "    _, _, test_df = split_data(df)\n",
    "\n",
    "    # 3) TF-IDF + SVM report \n",
    "    vec_svm = baseline_results[\"vec_svm\"]\n",
    "    clf_svm = baseline_results[\"clf_svm\"]\n",
    "    texts = test_df[\"clean_text\"].tolist()\n",
    "    y_true = test_df[\"label\"].tolist()\n",
    "    y_pred_svm = clf_svm.predict(vec_svm.transform(texts)).tolist()\n",
    "\n",
    "    res_svm = generate_report(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred_svm,\n",
    "        y_scores=None,\n",
    "        target_names=baseline_results[\"label_encoder\"].classes_.tolist(),\n",
    "        output_dir=\"reports\",\n",
    "        prefix=\"tfidf_svm_test\"\n",
    "    )\n",
    "    print(\"SVM report files:\", res_svm)\n",
    "\n",
    "    # 4) TF-IDF + LogisticRegression (tiene predict_proba) — opcional\n",
    "    vec_lr = baseline_results[\"vec_logreg\"]\n",
    "    clf_lr = baseline_results[\"clf_logreg\"]\n",
    "    y_pred_lr = clf_lr.predict(vec_lr.transform(texts)).tolist()\n",
    "    try:\n",
    "        y_scores_lr = clf_lr.predict_proba(vec_lr.transform(texts))\n",
    "    except Exception:\n",
    "        y_scores_lr = None\n",
    "\n",
    "    res_lr = generate_report(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred_lr,\n",
    "        y_scores=y_scores_lr,\n",
    "        target_names=baseline_results[\"label_encoder\"].classes_.tolist(),\n",
    "        output_dir=\"reports\",\n",
    "        prefix=\"tfidf_logreg_test\"\n",
    "    )\n",
    "    print(\"LogReg report files:\", res_lr)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dee0e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 1153/1153 [01:24<00:00, 13.61it/s]\n",
      "Evaluating RNN: 100%|██████████| 247/247 [00:02<00:00, 86.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.0412, val_acc=0.6754, val_f1=0.5241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RNN: 100%|██████████| 247/247 [00:03<00:00, 79.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: 0.6778438567632544 0.5282711240183233\n",
      "RNN report files: {'metrics_json': 'reports\\\\rnn_lstm_test_metrics.json', 'classification_csv': 'reports\\\\rnn_lstm_test_classification_report.csv', 'confusion_png': 'reports\\\\rnn_lstm_test_confusion_matrix.png', 'roc_png': 'reports\\\\rnn_lstm_test_roc.png', 'pr_png': 'reports\\\\rnn_lstm_test_pr.png', 'calibration_png': 'reports\\\\rnn_lstm_test_calibration.png'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from src.data.preprocess import load_data, encode_labels, split_data, texts_to_sequences\n",
    "from src.evaluation.metrics_report import generate_report\n",
    "from src.training.training import train_rnn  # solo si quieres entrenar aquí\n",
    "\n",
    "CSV_PATH = \"data/mental_health.csv\"\n",
    "\n",
    "def main():\n",
    "    rnn_res = train_rnn(CSV_PATH, model_type=\"lstm\", epochs=1) \n",
    "    model = rnn_res[\"model\"]\n",
    "    word2idx = rnn_res[\"word2idx\"]\n",
    "    label_encoder = rnn_res[\"label_encoder\"]\n",
    "\n",
    "    # reconstruir test_df\n",
    "    df = load_data(CSV_PATH)\n",
    "    df, _ = encode_labels(df)  \n",
    "    train_df, val_df, test_df = split_data(df)\n",
    "\n",
    "    # sequences\n",
    "    max_len = 70\n",
    "    test_seqs = texts_to_sequences(test_df[\"clean_text\"].tolist(), word2idx, max_len)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # predict in batch\n",
    "    with torch.no_grad():\n",
    "        X = torch.tensor(test_seqs, dtype=torch.long).to(device)\n",
    "        logits = model(X)\n",
    "        probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "    y_true = test_df[\"label\"].tolist()\n",
    "    y_pred = probs.argmax(axis=1).tolist()\n",
    "\n",
    "    res = generate_report(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        y_scores=probs,\n",
    "        target_names=label_encoder.classes_.tolist(),\n",
    "        output_dir=\"reports\",\n",
    "        prefix=\"rnn_lstm_test\"\n",
    "    )\n",
    "    print(\"RNN report files:\", res)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
